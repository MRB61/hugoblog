[{"content":"\rIgnorant thoughts presented in a structured manner.\r#\rI have some dedicated time throughout my week to think about anything. This is the outcome of those reflections.\n","date":"16 December 2025","externalUrl":null,"permalink":"/hugoblog/","section":"On everything","summary":"","title":"On everything","type":"page"},{"content":"\rMotivation\r#\rWe are almost through the first third of the 2025-26 NBA season, and as a Suns fan I want to discuss, trough data, the situation of the team and the league in general. As of 2025-12-16, 26 games in, we are 7th in the West with a record of 14-12. Given that we traded Kevin Durant and waived Bradley Beal, many people are deeming this start quite an impressive effort. Well, first I want to recall that last year\u0026rsquo;s Suns were the worst form of this team in the last 6 years, and yet we also started 14-12 through the first 26 games. This fact, combined with the amazing discovery of \u0026ldquo;nba_api\u0026rdquo; (https://github.com/swar/nba_api), led me to wonder what the data would actually say about this new team.\nComparison\r#\rThe team has changed, that I can\u0026rsquo;t deny. New coach, another great draft with Maluach, Fleming and Koby Brea, and the addition of key pieces in Dillon Brooks and Jalen Green. Before diving into the data, I want to note my reluctance to Jalen Green. I do not believe in his skillset and approach to the game, another high usage low accuracy guard near Booker is a recipe for dissaster. However, due to Jalen\u0026rsquo;s injury we have not seen them play together, thus I will not make any definitive assertions.\nLet\u0026rsquo;s look at a comparison of last year\u0026rsquo;s and this year\u0026rsquo;s basic stats and discuss them. Note all stats shown were taken per 100 possessions.\nThe first two rows are what I would call the Dillon Brooks effect. We are drawing more personal faults (PFD) and committing more fouls (PF). One should not look at this increase with bad eyes; it is actually a positive thing if handled correctly. Unfortunately Booker did not get the memmo. I take this space to note the amazing jump offensively that Dillon Brooks is having. Right now he has gone from 14 PPG to 21.6 PPG, if he keeps those numbers I would seriously consider him a contender for the MIP, even though he is already a stablished named in the league.\nContinuing down the chart, we are recieving more blocks and blocking fewer shots. This is just due to the clear difference in play style between Nurkic (previous center) and Mark Williams (actual center). We are also generating more steals while committing more turnovers. I want to focus on the steals because turnovers are what are driving me insane this season, and we will discuss them later on. We are playing a much more active basketball, mainly thanks to Dillon Brooks. This shift in energy had made almost every player step up in terms of steals, remarking Grayson Allen who is stealing 1 more whole ball.\nWe are dealing less assists because we don\u0026rsquo;t have KD to draw defensive attention, and now Booker is consistently facing the best defenders. Then the change in rebound distribution is, again, due to the change of center; Nurkic almost only took defensive boards, and Mark Williams is more of an offensive center. The rest is not that relevant. Percentages changes although impercetible due to scale, are minimal.\nNow we diving deeper into second opportunities and how we are dealing with those turnovers.\nAs I mentioned before, turnovers are a problem. As we loose more balls, we are getting penalized. However, this graphic also contains good news. Note that this new rapid style of play is allowing us to convert more off those turnovers. Not only that, the increase in offensive rebounds gives us more points on second chances. A suns fan might be hopeful reading this and thinking we might do something this year. Well, I feel like it is my job to crush those expectations. Let\u0026rsquo;s now compare ourselves with the rest of the league.\nThe graph y-axis is the pace, which represents how fast the team is playing in terms of possessions. It looks something like\n\\[\r\\text{PACE}=\\frac{240(\\text{Poss} _1+\\text{Poss} _2)}{2\\times \\text{TotalTeamMins}}\\]The x-axis is the net rating, which is simply the difference between offensive rating and defensive rating those, being statistics on how well the team attack and defend. the easy versions used by the nba (https://www.nba.com/stats/help/glossary) are \\[\\text{OFFRTG}=100 \\times \\frac{\\text{Points}}{\\text{Poss}}\\qquad \\text{DEFRTG}=100 \\times \\frac{\\text{OppPoints}}{\\text{OppPoss}}\\]Looking at the figure we can see that we are neither playing particularly fast nor winning by a margin. Nevertheless, one could argue that we are not in terrible shape if we look in our near radius. Current seeds 6 (Minessota), 4 (Spurs) and 3 (Lakers) are relatively close in terms of this statistics.\nNo comment on OKC. FUCK THEM.\nIt is only natural to see how this map looked last year.\nWe can appreciate the change in our pace, but so does almost all the leage in a sense. However, if we check our pace through the first 25 games of the last season, it is almost the same as portrayed in the graph above. It is true that we had better net rating due to that impressive start. Before moving on, Celtics pace is notably low in both graphs, they play a really three-focused brand of basketball which does not translate into fastbreaks and quick possesions.\nBooker shots distribution\r#\rWhen seeing the Suns these past years I have always felt that Booker was not playing his style of basketball. He went from a 4 APG player to a 7APG player, people like that he is involving his teammates more, but we must take into account the amount of effort that goes to looking for those assists. However, let\u0026rsquo;s see the data.\nThis chart is composed by two. The top one portrays the FGA attempts distribution on the court throughout Booker's career. I left corner threes out because it is not his main shot, and has not changed in volume. The bottom chart represents the FG pertentage of each location on top of eachother. The data is with me in terms that the volume of above the break 3's is getting out of hand, with last year being the highest. Last year split is just ludicrous, not only he shot 470 above the break 3's with a 30% accuracy, he got to the paint more times than mid range shots for the first time in his whole career while having less accuracy on those shots. It is completely baffling to me how no one is paying attention to this, because, it is where all the offense starts. For now, I will not comment on the data of this year's season, the clear less amount of attempts is due to the fact that wea are only a third into the season, and the whopping 29% on threes won't be commented on either for my sanity.\rMy favourite versions of the Suns where 2020-2021 (the finals team), and 2022-23 when we got KD mid season and were really good in the playoffs, ultimately we lost to Denver who continued to win it all. Now let\u0026rsquo;s look at the chart for those two seasons, what does it have in common?\nTHE DISTRIBUTION WAS MUCH MORE UNIFORM!! Booker was much more versatile those seasons. When you threat with several shots or possibilities the rival deffense must adapt, which is not that easy. Data back what my eyes are seeing, running point is limiting his offense in the sense that the shots he recieves now are much more concentrated in terms of kind.\nConlcusion\r#\rWe\u0026rsquo;ll see how the season develop. GO SUNS!\n","date":"16 December 2025","externalUrl":null,"permalink":"/hugoblog/posts/nba/","section":"Posts","summary":"Post NBA","title":"On the Suns and the 2025-26 NBA season","type":"posts"},{"content":"","date":"16 December 2025","externalUrl":null,"permalink":"/hugoblog/posts/","section":"Posts","summary":"","title":"Posts","type":"posts"},{"content":"\rOn this post I intend to present some thoughts I have gathered when coming across 1. How I found that paper is a good starting point. I had the idea of representing the network of “Mathematics”, its own fields and how they are connected. The initial objective was to portray the obvious idea that not even Mathematics escape trends. You can find the product of those thoughts in the miscellaneous section.\nHowever, when working with Wikipedia as a network, I observed that the “relevant” information, i.e., the information that “matters” when introducing a new vertex, was diluting when increasing the graph size: new vertices rarely linked with old vertices. Obviously there is some fault in how I designed the algorithm and structured the network exploration. Nevertheless, there was something mathematically interesting under it. Thus, I searched on arXiv for the latest preprints on this topic and found 1.\nLet’s lay down some groundwork:\nWe denote \\(\\{\\mathcal{T}_n : n \\geq 1\\}\\) a sequence of trees, and \\(B(T,r)\\) the tree up to distance \\(r\\) from the root. Unfortunately they denote \\(\\mathbb{T}\\) the space of $\\textbf{finite}$ trees; one accustomed to other fields might see the circle. This space is endowed with the following distance. For \\(t,s \\in \\mathbb{T}\\),\n\\[ d(t,s) := \\frac{1}{1 + R^*} \\qquad R^* = \\sup\\{ r : B(t,r) \\sim B(s,r) \\}. \\] t\rs\rOn that figure, clearly \\(d_{\\mathbb{T}}(t,s)=1\\) because even at distance \\(1\\) from the root they are not isomorphic. This also tells us that \\(d_{\\mathbb{T}}(t,s) \\leq 1\\) for any \\(t,s \\in \\mathbb{T}\\). One must note that, thanks to the supremum, we can achieve distance \\(0\\): if \\(t,s\\) are both isomorphic up to their maximal distance, i.e. their height, say \\(n\\), then they are also isomorphic up to \\(n+1\\).\nNow a concept central to everything we will work on later is the decomposition of a tree into its subtrees, or fringes. Given a walk inside the tree \\(t\\) from vertex to root, \\((v_0, v_1, \\dots, v_h = \\rho)\\), we can decompose the tree uniquely into \\(h+1\\) trees \\(f_0(v,t), \\dots, f_h(v,t)\\), where \\(f_i(v,t)\\) is the tree rooted at \\(v_i\\) with all the vertices for which there exists a walk in \\(t\\) from the root passing through \\(v_i\\) but not \\(v_{i-1}\\). This is just the mathematical way of partitioning the tree from bottom to top. A representation is due:\nTree\rIf we take the penultimate vertex from the right and take the unique path to the root, the fringe decomposition would be the following f_0\rf_1\rf_2\rf_3\rNow, if we take each $f_i$ and join their roots in order we would recover the original tree.\nWe now formalise these ideas with the space of sequences of trees and the notion of fringe decomposition.\nLet \\(\\mathbb{T}\\) be the space of finite rooted trees equipped with the metric \\(d_{\\mathbb{T}}\\) defined above, and let \\[ \\mathbb{T}^{\\infty} := \\big\\{ (t_0,t_1,\\dots) : t_i \\in \\mathbb{T} \\text{ for all } i \\ge 0 \\big\\} \\] be the space of sequences of finite trees.\nGiven a rooted tree \\(t \\in \\mathbb{T}\\) and a vertex \\(v\\) of \\(t\\), we define the fringe decomposition of \\(t\\) along the path from \\(v\\) to the root by \\[ F(v,t) = \\bigl( f_0(v,t),f_1(v,t),\\dots,f_h(v,t),\\varnothing,\\varnothing,\\dots \\bigr) \\in \\mathbb{T}^{\\infty}, \\] where \\(f_i(v,t)\\) is the subtree of \\(t\\) rooted at the \\(i\\)-th vertex on the (unique) path from \\(v\\) to the root, and \\(h\\) is the length of that path.\nFor \\(k \\ge 0\\) we write \\[ F_k(v,t) := \\bigl( f_0(v,t),\\dots,f_k(v,t),\\varnothing,\\varnothing,\\dots \\bigr), \\] and we call \\(f_0(v,t)\\) the fringe of \\(t\\) at \\(v\\).\nOn \\(\\mathbb{T}^{\\infty}\\) we extend the metric \\(d_{\\mathbb{T}}\\) by \\[ d_{\\mathbb{T}^{\\infty}} \\bigl( (t_0,t_1,\\dots),(s_0,s_1,\\dots) \\bigr) := \\sum_{i=0}^{\\infty} \\frac{1}{2^{i}}\\, d_{\\mathbb{T}}(t_i,s_i). \\]An element \\[ \\omega = (t_0,t_1,\\dots) \\in \\mathbb{T}^{\\infty} \\quad\\text{with}\\quad |t_i| \\ge 1 \\text{ for all } i \\ge 0 \\] can be viewed as a locally finite infinite rooted tree with a unique infinite path, in the following way.\nTo obtain the infinite tree, identify the collection of fringes \\(\\{t_i : i \\ge 0\\}\\) with the positive integers \\(\\mathbb{Z}_+\\) and add nearest–neighbour edges between the roots of \\(t_i\\) and \\(t_{i+1}\\) for each \\(i \\ge 0\\). In other words, we join the roots of the fringes along a single infinite ray \\[ t_0 \\text{ -- } t_1 \\text{ -- } t_2 \\text{ -- } \\cdots , \\] and attach each finite tree \\(t_i\\) at its root. The resulting object is an infinite, locally finite tree with a unique infinite path.\nFor each \\(k\\) we may look at the truncated sequence \\[ F_k(0,\\omega) = (t_0,\\dots,t_k), \\] and we call \\(t_0\\) the fringe of the sin-tree associated with \\(\\omega\\).\nIntro\r#\rNow, after we have the basics of the $\\mathbb{T}$ space, we can state their model and how it differs the classical uniform tree. They construct a sequence of trees ${\\mathcal{T}_n}$ in the following way:\n$\\mathcal{T}_1$ is the root Each $n$ we add a vertex and assign the edge $e_{n,k}$ uniformly following \\[\\mathbb{P}(k=v)=1_{\\{j(n)\\leq v \\leq n\\}}\\] where $j(n): \\mathbb{N}\\rightarrow \\mathbb{N}$ non-decreasing function such that $j(n)\\leq n : \\forall n\\geq 1$. One must think of the function $j(n)$ as dilution of information I mentioned on the intro.\nObservation\nThe original paper has a $f(D_n(v))$ function in front of the indicator for the cases when one want to take into account the degree of the vertex. Also, note that taking $j(n)=1$ is just the standard random tree. The paper consider the following functions \\[j(n)=\\lfloor \\beta n\\rfloor \\qquad j(n)=n-\\lfloor n^{\\beta} \\rfloor\\] with $\\beta\\in (0,1)$. In order to understand what the paper problem is, let\u0026rsquo;s first do some simulations. In order,\n$\\beta=0.3$\r$\\beta=0.7$\rThis regime looks quite like a standard uniform random tree. However,\n$\\beta=0.3$\r$\\beta=0.7$\rThere is a major change in geometry, one would suspect there is a phase transition in $\\beta=0.5$. The whole objective of their paper is to understand these processes when $n\\rightarrow \\infty$. But for us to even approach that, we should first understand how or to what can a sequence of trees converge.\nConvergence on the space of trees\r#\rLet \\(\\{\\mathcal{T}_n\\}_{n\\ge 1}\\) be a sequence of rooted trees. For \\(n\\ge 1\\) and each fixed \\(k\\ge 0\\), we define the empirical distribution of the fringes up to distance \\(k\\) by\n\\[ \\mathcal{B}_n^{(k)} := \\frac{1}{n}\\sum_{v\\in \\mathcal{T}_n} \\delta_{F_k\\bigl(v,\\mathcal{T}_n\\bigr)}. \\]Thus \\(\\{\\mathcal{B}_n^{(k)}\\}_{n\\ge 1}\\) can be viewed as a sequence of random probability measures on the space \\(M(\\mathbb{T}^k)\\).\nFix a probability measure \\(\\omega\\) on \\(\\mathbb{T}\\).\nWe say that the sequence of trees \\(\\{ \\mathcal{T}_n \\}\\) converges in expectation in the fringe sense to \\(\\omega\\) if \\[ \\mathbb{E}\\bigl[\\mathcal{B}_n^{(0)}\\bigr]\\;\\to\\; \\omega \\qquad\\text{as } n\\to\\infty. \\] We say that \\(\\{\\mathcal{T}_n\\}\\) converges in probability in the fringe sense to \\(\\omega\\) if \\[ \\mathcal{B}_n^{(0)} \\;\\to\\; \\omega \\] in probability, with respect to the weak topology on measures (Portmanteau).\nWe say that \\(\\{\\mathcal{T}_n\\}\\) converges in probability in the extended fringe sense to a limiting infinite random sin-tree \\(\\mathcal{T}_\\infty\\) if, for all \\(k\\ge 0\\), \\[ \\mathcal{B}_n^{(k)} \\;\\to\\; \\mathbb{P}\\bigl(F_k(0,\\mathcal{T}_\\infty)\\in \\cdot\\bigr), \\] again in the weak sense, taking the right-hand side as a probability measure on \\(\\mathbb{T}^k\\).\nIt is immediate that if we take the fixed measure \\(\\omega\\) to be the law of the fringe of \\(\\mathcal{T}_\\infty\\) on \\(\\mathbb{T}\\), that is \\[ \\omega(\\cdot) = \\mathbb{P}\\bigl(F_0(0,\\mathcal{T}_\\infty)\\in \\cdot\\bigr), \\] then convergence in the extended fringe sense implies convergence in probability in the fringe sense.\nAldous developed the general theory of fringe distributions 2 and many related results; his work on extremal points of the corresponding space of measures is particularly powerful. We will later use that, in fact, if one works with an extremal distribution (in terms of point inside said convex space), convergence in means is sufficient.\nResults\r#\rHere I state the two results that interest me most.\nResult 1.\nFor the case \\(j(n)=\\lfloor \\beta n\\rfloor\\) with \\(\\beta\\in(0,1)\\), the sequence \\(\\{\\mathcal{T}_n\\}\\) converges in the extended fringe sense to a distribution \\(\\omega_\\beta\\).\nHere \\(\\omega_\\beta\\) is the distribution of the standard branching process driven by a Poisson process \\(N_\\beta\\) with rate \\((1-\\beta)^{-1}\\) on the time interval \\([0,\\log(\\beta^{-1})]\\), observed at a random time \\(T_1\\), where \\(T_1\\sim \\mathrm{Exp}(1)\\).\nThe mere fact that one can write down the limiting distribution explicitly is, to me, quite striking.\nResult 2.\nFor the case \\(j(n)=n-\\lfloor \\beta n\\rfloor\\) with \\(\\beta\\in(0,1)\\), the sequence \\(\\{\\mathcal{T}_n\\}\\) converges in the extended fringe sense to the unique infinite sin-tree whose fringe distribution is \\(\\omega_{P,1}\\).\nThe measure \\(\\omega_{P,1}\\) is the law of a standard critical Galton–Watson branching process with Poisson offspring distribution of mean \\(1\\). Notice that this limit is independent of \\(\\beta\\), and in fact coincides with the local weak limit of a uniform random tree.\nOne might suspect that this contradicts the geometric differences we observed earlier, but these are local results. In fact, they covered the global geometry and phase transitions in a topological framework (via Gromov–Hausdorff convergence).\nOutline proof 1\r#\rWe call \\(T_k^n\\) the time at which the \\(k\\)-th child of vertex \\(n\\) arrives; i.e. \\[ T_k^n := \\inf\\{\\ell : \\deg(n,\\mathcal{T}_\\ell) = k+1\\}, \\] and \\(\\rho_j^n\\) the \\(j\\)-th vertex in the fringe of \\(n\\).\nWe then define, for \\(j\\ge 0\\) and \\(k\\ge 1\\), \\[ T_{j,k}^n := T_k^{\\rho_j^n}, \\qquad \\tau_{j,k}^n := \\log\\!\\left(\\frac{T_{j,k}^n}{T_{j,k-1}^n}\\right), \\] the arrival time between \\(k-1\\) and \\(k\\) inside the fringe of \\(\\rho_j^n\\).\nThey show, with some effort, that \\[ \\bigl((\\tau_{j,k}^n),\\: j\\geq 0\\bigr) \\;\\xrightarrow{d}\\; \\bigl((\\mathcal{E}_ {j,k}), \\:j\\geq 0 \\bigr), \\] where \\(\\mathcal{E}_ {j,k}\\) are the arrival times of \\(N_\\beta\\).\nIn fact, if we consider our process in logarithmic time, vertex \\(j\\ge 2\\) appears at time \\(\\log j\\), and a uniformly chosen vertex appears at time \\[ \\log n - \\log \\lfloor nU\\rfloor, \\] where \\(U\\sim \\mathrm{Unif}(0,1)\\).\nWe now rely on the following construction. Given \\(t\\in\\mathbb{R}_+\\) and \\(w\\in\\mathbb{R}^{\\mathbb{N}\\times\\mathbb{N}}\\) we can construct a finite tree \\[ \\mathbf{T}(t,w)\\in\\mathbb{T} \\] by taking, for \\(j\u003e0\\), \\(k\\ge 1\\), that \\(w_{j,k}\\) is the age of vertex \\(j\\) when its \\(k\\)-th child is born.\nWe keep all vertices that satisfy \\(w_{j,k}\\le t\\). For \\(0\\le j\\le \\mathbf{T}(t,w)\\) we denote by \\(\\tau_j(t,w)\\) the birth time of the \\(j\\)-th vertex of \\(\\mathbf{T}(t,w)\\) and set \\[ n(t,w) := \\sup\\{j\\ge 0 : \\tau_j(t,w)\\le t\\}, \\] the last vertex we have with birth time less than \\(t\\), i.e. the height.\nWe define \\[ \\mathbf{W} := \\{(t,w) : n(t,w)\u003c\\infty,\\ \\tau_{j}(t,w)\\neq t\\}, \\] and thus \\(\\mathbf{T}:\\mathbf{W}\\to\\mathbb{T}\\) is continuous.\nApplying this to the discrete construction above, we can write the fringe of a uniformly chosen vertex \\(\\ell\\) as \\[ \\mathbf{T}\\bigl(\\log n - \\log \\lfloor nU\\rfloor,\\; W^{\\lfloor nU\\rfloor}\\bigr), \\] where \\(W^{\\lfloor nU\\rfloor}\\) is the matrix formed by the \\(\\tau^{\\lfloor nU\\rfloor}_{j,k}\\).\nBy the convergence of the inter-arrival times, \\[ \\bigl(\\log n - \\log \\lfloor nU\\rfloor,\\; W^{\\lfloor nU\\rfloor}\\bigr) \\;\\xrightarrow{d}\\; \\bigl(T_1, W^*\\bigr), \\] where \\(T_1\\sim\\mathrm{Exp}(1)\\) and \\(W^*\\) is the matrix associated to \\((\\mathcal{E}_ {j,k})\\). By the continuous mapping theorem, \\[ \\mathbf{T}\\bigl(\\log n - \\log \\lfloor nU\\rfloor,\\; W^{\\lfloor nU\\rfloor}\\bigr) \\;\\xrightarrow{d}\\; \\mathbf{T}(T_1,W^*), \\] which has distribution \\(\\omega_\\beta\\).\nOutline proof 2\r#\rAgain the idea is to approximate the discrete tree using a continuous time branching process. In fact, what we approximate is the BFS of the fringe of a vertex in the \\(\\mathcal{T}_ n\\).\nA lemmas is needed, approximate de degree of vertex \\(j\\) at time \\(n \\equiv D_{j,n}\\) by a \\(Poiss(1)\\).\nLemma. Let \\(D_{j,n}\\) as before. For any \\(\\delta\u003e1\\), there exists \\(j_0\\) such that\n\\[ d\\bigl(D_{j,n}, \\text{Pois}(1)\\bigr) \\le \\delta\\bigl(1-(1+\\delta j^{\\beta-1})^{-\\beta}\\bigr)+\\delta j^{-\\beta} +\\max(\\delta-1, j^{-\\beta}) +\\mathbf{1}_{\\{N_j \\ge n-j\\}} \\left|\\frac{n-j}{j^\\beta}-1\\right|, \\] where \\(d\\) is just the total variation distance between distributions and \\[ N_j := |\\{i : i-i^\\beta \\le j \u003c i\\}|. \\]In order to proceed we need to understand \\(N_j\\). Recall that we are under the regime \\(j(n)=n-\\lfloor n^\\beta \\rfloor\\) so \\(N_j\\) just tells us the amount of vertices that have access to \\(j\\). Thus also tells us the max possible vertex that could reach \\(j\\).\nNow, the expression above just partition the cases on whether the vertex \\(j\\) is reachable at time \\(n\\), \\(N_j \\le n\\) or not. We first need to understand some properties of \\(N_j\\).\nLemma. We have\ni) \\(N_j \\ge j^{\\beta}-1\\), \\(j\u003e1\\).\nii) For any \\(\\delta\u003e1\\), there exists \\(j_0\u003e1\\) such that \\[ N_j \\le \\delta j^\\beta \\qquad \\forall j\\ge j_0. \\]Proving this is almost immediate.\nFor i) just note that \\(\\lfloor j^\\beta\\rfloor \\le (j+\\lfloor j^\\beta\\rfloor)^\\beta\\) because \\(\\lfloor j^\\beta\\rfloor \\le \\lfloor j\\rfloor ^{\\beta}\\) and \\( \\lfloor j\\rfloor \\le j+\\lfloor j^\\beta\\rfloor\\).\nThus, \\[ (j+\\lfloor j^\\beta\\rfloor) - (j+\\lfloor j^\\beta\\rfloor)^\\beta \\le j, \\] and because \\(N_j\\) is the biggest index such that \\(i-i^\\beta \\le j\\) we have \\[ N_j \\ge j+\\lfloor j^\\beta\\rfloor \\ge j^\\beta-1. \\]For (ii) the argument is quite amusing. If \\[ (j+\\delta j^\\beta) - (j+\\delta j^\\beta)^\\beta \\le j, \\] then \\[ \\delta = (1+\\delta j^{\\beta-1})^{-\\beta}. \\] When \\(j\\to\\infty\\) the right side tends to \\(1\\).\nHence if \\(\\delta\u003e1\\) there must be a \\(j_0\\) such that \\[ (j_0+\\delta j_0^\\beta) - (j_0+\\delta j_0^\\beta)^\\beta \\ge j_0. \\] \\(\\Rightarrow \\delta j_0^\\beta \u003e N_j \\quad \\forall j\\ge j_0.\\)\nNow the proof of the original lemma follows.\nTaking \\(j\\leq i \\) \\[ Y_{i,j} = \\mathbf{1}_{\\{ i \\text{ connects to } j \\}}. \\] Thus, \\[ Y_{i,j} \\equiv \\text{Ber}\\!\\left(\\frac{\\mathbf{1}_{\\{i-i^\\beta \\le j\\}}}{i^\\beta}\\right) \\] because the positive case is when \\(i-i^\\beta\\le j\\) and the total possibilities are \\((i-(i-i^\\beta))=i^\\beta\\).\nAlso take \\[ N_{j,n} = \\min\\{N_j,\\, n-j\\}. \\]We approximate the degree summing up these Bernoullis, thus using the lemma we state that for \\(j\\) large enough, we can bound the \u0026ldquo;error\u0026rdquo; by \\[ d\\bigl(D_{j,n}, \\text{Bin}(N_{j,n}, j^{-\\beta})\\bigr) \\le \\sum_i \\mathbf{1}_{\\{i-i^\\beta \\le j\\}} \\left| j^{-\\beta} - i^{-\\beta} \\right| \\le N_{j,n}\\left| j^{-\\beta} - (j+\\delta j^\\beta)^{-\\beta} \\right| \\le \\delta\\bigl(1-(1+\\delta j^{\\beta-1})^{-\\beta}\\bigr). \\]Now we approximate the binomial with a Poisson(1): \\[ d\\bigl(\\text{Bin}(N_{j,n}, j^{-\\beta}), \\text{Poiss}(1)\\bigr) \\le d\\!\\left(\\text{Bin}(N_{j,n}, j^{-\\beta}), \\text{Poiss}\\!\\left(\\frac{N_{j,n}}{j^\\beta}\\right)\\right) + d\\!\\left(\\text{Poiss}\\!\\left(\\frac{N_{j,n}}{j^\\beta}\\right), \\text{Poiss}(1)\\right) \\] \\[ \\le \\frac{N_{j,n}}{j^{2\\beta}} + \\left|\\frac{N_{j,n}}{j^\\beta} - 1\\right|. \\]Using \\(N_{j,n}\\le \\delta j^\\beta\\) and \\[ \\left|\\frac{N_{j,n}}{j^\\beta}-1\\right| \\le \\left|\\frac{N_j}{j^\\beta}-1\\right| + \\mathbf{1}_{\\{N_j\u003en-j\\}}\\left|\\frac{n-j}{j^\\beta}-1\\right| \\] we obtain the desired inequality \\[ d\\bigl(D_{j,n}, \\text{Poiss}(1)\\bigr) \\le \\delta\\bigl(1-(1+\\delta j^{\\beta-1})^{-\\beta}\\bigr)+\\delta j^{-\\beta}+ \\max(\\delta-1, j^{-\\beta})+ \\mathbf{1}_{\\{N_j\u003en-j\\}}\\left|\\frac{n-j}{j^\\beta}-1\\right|. \\] The proof of the result now stems from the Aldous extremal point tool mentioned. We just have to show.\nFor a tree \\(\\mathcal{T}\\in\\mathbb{T}\\) with \\(|\\mathcal{T}|=k\\), \\(U\\equiv \\text{Unif}(0,1)\\),\n\\[\\lim_{n\\to\\infty} \\mathbb{P}\\bigl(F(\\lfloor nU\\rfloor, \\mathcal{T}_ n)=\\mathcal{T} \\bigr)=\\lim_{n\\to\\infty}\\int^{1}_ {0} \\mathbb{P}\\bigl(F(\\lfloor nu\\rfloor, \\mathcal{T}_ n)=\\mathcal{T} \\bigr) du \\rightarrow \\mathbb{P}(w_{Poiss,1}=\\mathcal{T} )\\]For this, fix \\(u\\in[0,1]\\). Tomamos la BFS of the fringe of \\(T_n^u\\), where we stop if the \\(\\lfloor nu\\rfloor\\) fringe differs from \\(T\\) or if it is equal to \\(T\\). Recall at most we encounter \\(k\\).\nThey argue the \\(k\\) explorated vertices are all such \\(N_j\\le nu\\).\nUsing previous lemma with \\(\\delta=2\\) there exists \\(N\\in\\mathbb{N}\\) such that the index of any vertex attatching to \\(j\\) for \\(j \\geq N\\) is bounded by \\(j+2j^\\beta\\). Thus for \\(n\\ge N/u\\) the index of the vertex that attaches to \\(\\lfloor nu\\rfloor\\) is bounded by \\(nu+2(nu)^\\beta\\). We could iterate this idea so the index of the \\(k\\) vertex attatching the fringe is bounded by \\[ nu+2(nu)^\\beta+2(nu+2(nu)^\\beta)^\\beta + \\cdots= nu+O(n^\\beta). \\] Thus the lemma tells us that those \\(k\\) vertices are good at time \\(n\\), i.e. \\(N_j\\le nu\\).\nNow just take \\(\\delta\u003e1\\Rightarrow \\exists \\widetilde{N}\u003eN_u\\) such that \\(1\\le j \\le k\\) \\[ d\\bigl(D_{j,n}, \\text{Poiss}(1)\\bigr) \\le \\delta\\bigl(1-(1+\\delta j^{\\beta-1})^{-\\beta}\\bigr)+ \\delta j^{-\\beta}+\\max(\\delta-1, j^{-\\beta}) \\qquad\\forall n\\ge \\widetilde{N}. \\] We conclude by\n\\[\\limsup_{n\\to\\infty} \\left| \\mathbb{P}\\left(F(\\lfloor nu \\rfloor,\\mathcal{T}_ n)=\\mathcal{T} \\right)-\\mathbb{P}\\left(w_{Poiss,1}=\\mathcal{T} \\right)\\right| \\leq k(\\delta-1) \\quad \\forall \\delta \u003e1. \\]\rConclusion\r#\rI had a lot of fun reading the paper, it is true that they go on to analyze the geometry and height of each regime, but I was mainly interested in the concept of local weak convergence.\nI had the idea of considering the regime \\(j(n)= n- \\lfloor ln(n) \\rfloor \\) but one may note that for any \\(\\beta \\in (0,1)\\), \\(n-ln(n)\\geq n-\\lfloor n^{\\beta} \\rfloor\\). Thus the overall result should be the same, representationwise looks pretty similar to taking a small \\(\\beta\\)\n$j(n)=n-\\lfloor ln(n)\\rfloor $\r$j(n)=n-\\lfloor ln(n^{1/3}) \\rfloor $\rOmer Angel, Shankar Bhamidi, Serte Donderwinkel, Neeladri Maitra, Akshay Sakanaveeti, Evolution of recursive trees with limited memory, arXiv:2510.18856\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nD. Aldous, Asymptotic fringe distributions for general families of random trees, The Annals of Applied Probability (1991), 228–266\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"1 December 2025","externalUrl":null,"permalink":"/hugoblog/posts/trees/","section":"Posts","summary":"Post on Random Trees with limited memory","title":"On random trees with limited information","type":"posts"},{"content":"","externalUrl":null,"permalink":"/hugoblog/authors/","section":"Authors","summary":"","title":"Authors","type":"authors"},{"content":"","externalUrl":null,"permalink":"/hugoblog/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"},{"content":"Here I pretend to dump figures I found interesting or simple experiments that do not require theoretical explanation.\nRandom walk through Wikipedia: link.\nThe Mathematics network (It takes some time to load): link.\nTop 30 players in FGA with their TS on the first 25 games of the 2025-26 NBA season:\nShow chart ","externalUrl":null,"permalink":"/hugoblog/misc/","section":"Miscellaneous","summary":"","title":"Miscellaneous","type":"misc"},{"content":"","externalUrl":null,"permalink":"/hugoblog/series/","section":"Series","summary":"","title":"Series","type":"series"},{"content":"","externalUrl":null,"permalink":"/hugoblog/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"}]